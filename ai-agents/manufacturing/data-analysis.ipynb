{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "976711e9",
   "metadata": {},
   "source": [
    "Manufacturing AI Agent\n",
    "\n",
    "- Install Dependencies\n",
    "  \n",
    "```bash \n",
    "pipenv shell\n",
    "pipenv install langchain langchain-google-genai\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a48ad4ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain.memory import ConversationBufferWindowMemory\n",
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "# --- Setup ---\n",
    "GOOGLE_API_KEY = os.getenv(\"GOOGLE_API_KEY\")\n",
    "\n",
    "# Initialize Gemini LLM\n",
    "llm = ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-pro\",\n",
    "    temperature=0.3,\n",
    "    google_api_key=GOOGLE_API_KEY\n",
    ")\n",
    "\n",
    "# Initialize short-term memory (buffer of last 5 messages)\n",
    "memory = ConversationBufferWindowMemory(k=5, return_messages=True)\n",
    "\n",
    "# System prompt for structured agent behavior\n",
    "SYSTEM_PROMPT = \"\"\"\n",
    "You are a specialized control chart monitoring agent in a manufacturing environment.\n",
    "Your role is to observe new sensor readings and determine process stability using SPC (Statistical Process Control) logic.\n",
    "\n",
    "Use this structured output:\n",
    "@observe: Acknowledge the new reading.\n",
    "@reason: Explain trend status or SPC rule violations, referencing the trend window.\n",
    "@act: Recommend what action to take (e.g., monitor, alert supervisor, prep shutdown).\n",
    "\"\"\"\n",
    "\n",
    "# Sample input (you can swap this out for other sensor messages)\n",
    "sensor_data = {\n",
    "    \"sensor\": \"vibration_motor_3A\",\n",
    "    \"timestamp\": \"2025-06-18T11:47:09Z\",\n",
    "    \"value\": 0.89,\n",
    "    \"unit\": \"mm/s\",\n",
    "    \"ucl\": 0.90,\n",
    "    \"lcl\": 0.50,\n",
    "    \"trend_window\": [0.91, 0.94, 0.86, 0.89],\n",
    "    \"alert_enabled\": True\n",
    "}\n",
    "\n",
    "# Prepare prompt\n",
    "formatted_data = json.dumps(sensor_data, indent=2)\n",
    "prompt = f\"{SYSTEM_PROMPT}\\n\\nNew telemetry data:\\n{formatted_data}\"\n",
    "\n",
    "# Run LLM with memory context\n",
    "response = llm.invoke([HumanMessage(content=prompt)])\n",
    "\n",
    "# Save exchange to memory\n",
    "memory.save_context({\"input\": formatted_data}, {\"output\": response.content})\n",
    "\n",
    "# Print the response\n",
    "print(\"\\n===== AGENT RESPONSE =====\")\n",
    "print(response.content)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python-dNT3Lhuf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
