{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "976711e9",
   "metadata": {},
   "source": [
    "Manufacturing AI Agent\n",
    "\n",
    "- Install Dependencies\n",
    "  \n",
    "```bash \n",
    "pipenv shell\n",
    "pipenv install langgraph langchain langchain-google-genai\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a48ad4ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, END\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain.memory import ConversationBufferWindowMemory\n",
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "# --- LLM Setup ---\n",
    "llm = ChatGoogleGenerativeAI(model=\"gemini-pro\", temperature=0.3)\n",
    "\n",
    "# --- Memory Setup ---\n",
    "memory = ConversationBufferWindowMemory(k=5, return_messages=True)\n",
    "\n",
    "# --- System Prompt ---\n",
    "SYSTEM_PROMPT = \"\"\"\n",
    "You are a specialized control chart monitoring agent in a manufacturing environment.\n",
    "Your job is to assess whether a process is trending out of control based on sensor readings and SPC rules.\n",
    "\n",
    "Use this format:\n",
    "@observe: Acknowledge the new reading.\n",
    "@reason: Explain trend status or SPC rule violations.\n",
    "@act: Recommend an action (e.g., monitor, alert supervisor, prep shutdown).\n",
    "\"\"\"\n",
    "\n",
    "# --- Sample Input ---\n",
    "sensor_data = {\n",
    "    \"sensor\": \"vibration_motor_3A\",\n",
    "    \"timestamp\": \"2025-06-18T11:47:09Z\",\n",
    "    \"value\": 0.89,\n",
    "    \"unit\": \"mm/s\",\n",
    "    \"ucl\": 0.90,\n",
    "    \"lcl\": 0.50,\n",
    "    \"trend_window\": [0.91, 0.94, 0.86, 0.89],\n",
    "    \"alert_enabled\": True\n",
    "}\n",
    "\n",
    "# --- Define Nodes ---\n",
    "def ingest(state):\n",
    "    return {\"sensor_data\": state[\"input\"]}\n",
    "\n",
    "def analyze(state):\n",
    "    formatted = f\"{SYSTEM_PROMPT}\\n\\nNew telemetry data:\\n{state['sensor_data']}\"\n",
    "    response = llm.invoke([HumanMessage(content=formatted)])\n",
    "    memory.save_context({\"input\": state[\"sensor_data\"]}, {\"output\": response.content})\n",
    "    return {\"response\": response.content}\n",
    "\n",
    "def output(state):\n",
    "    print(\"\\n===== AGENT RESPONSE =====\")\n",
    "    print(state[\"response\"])\n",
    "    return state\n",
    "\n",
    "# --- Build Graph ---\n",
    "graph = StateGraph()\n",
    "graph.add_node(\"ingest\", ingest)\n",
    "graph.add_node(\"analyze\", analyze)\n",
    "graph.add_node(\"output\", output)\n",
    "\n",
    "graph.set_entry_point(\"ingest\")\n",
    "graph.add_edge(\"ingest\", \"analyze\")\n",
    "graph.add_edge(\"analyze\", \"output\")\n",
    "graph.add_edge(\"output\", END)\n",
    "\n",
    "# --- Compile and Run ---\n",
    "app = graph.compile()\n",
    "app.invoke({\"input\": sensor_data})\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python-dNT3Lhuf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
