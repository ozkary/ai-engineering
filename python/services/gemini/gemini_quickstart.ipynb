{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to use the AI Gemini API\n",
    "\n",
    "## Prerequisites\n",
    "- Use Python 3.9\n",
    "- Install the google-generativeai SDK\n",
    "- Get an API key from Google AI Studio https://aistudio.google.com/app/apikey\n",
    "- Copy your key and move it to the home directory of the VM or device\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sys.version_info(major=3, minor=9, micro=5, releaselevel='final', serial=0)\n"
     ]
    }
   ],
   "source": [
    "# verify python 3.9\n",
    "import sys\n",
    "print(sys.version_info)\n",
    "assert sys.version_info >= (3, 9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upgrade to Python 3.9 Ubunto\n",
    "\n",
    "- Search if the version of python is available in the current Ubuntu repos\n",
    "\n",
    "```bash\n",
    "apt search python3.9\n",
    "```\n",
    "\n",
    "- if packages are listed. Install with the following command\n",
    "\n",
    "```bash\n",
    "sudo apt install python3.9\n",
    "```\n",
    "\n",
    "- If the package is not listed, download the entire file and install from the command line.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get your API key from Google AI Studio\n",
    "\n",
    "[https://aistudio.google.com/app/apikey](https://aistudio.google.com/app/apikey)\n",
    "\n",
    "- Copy the key\n",
    "\n",
    "## Update the API key in your environment\n",
    "\n",
    "Using a terminal, run the save_key.sh bash file and enter the key at the prompt.\n",
    "\n",
    "This script will do the following:\n",
    "\n",
    "- Create a $Home/.gcp folder\n",
    "- Save the API key in the gemini.key file by running this bash file\n",
    "- Add a new environment variable GEMINI_KEY\n",
    "\n",
    "```bash\n",
    "./save_key.sh\n",
    "```\n",
    "\n",
    "> For production environments, set the correct permissions for that file or use a keyvault (recommended)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup a virtual environment\n",
    "\n",
    "- We recommend the use of a virtual environment to run this.\n",
    "```bash\n",
    "pip install pipenv\n",
    "pipenv shell\n",
    "```\n",
    "\n",
    "> You can run this without `pipenv` by installing only the dependencies locally"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install the Gemini API dependencies from the terminal\n",
    "\n",
    "- Use PIPEnv to update the depencies\n",
    "```bash\n",
    "pipenv shell\n",
    "pipenv sync\n",
    "```\n",
    "> pipenv sync installs the dependencies from the Pipfile\n",
    "\n",
    "\n",
    "- Or manually install the dependencies (No pipEnv)\n",
    "\n",
    "## Install the API requests module\n",
    "```bash\n",
    "pipenv install -q google-generativeai\n",
    "pipenv install requests\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the code example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ozkary/.local/share/virtualenvs/python-dNT3Lhuf/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# import the GEMINI API\n",
    "import google.generativeai as gemini\n",
    "\n",
    "# get the key reference\n",
    "api_key = os.getenv('GEMINI_KEY')\n",
    "model_name = 'gemini-pro'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**LLM Models for Code Generation**\n",
      "\n",
      "**Introduction:**\n",
      "\n",
      "Large Language Models (LLMs) are AI models with the ability to understand and generate human-like text. Their capabilities extend to generating code, making them valuable tools for developers.\n",
      "\n",
      "**How LLM Models Work:**\n",
      "\n",
      "* LLMs are trained on vast datasets of code and text, enabling them to learn programming syntax and the semantics of code.\n",
      "* When a developer provides an input prompt describing their desired functionality, the LLM generates a code snippet that fulfills the request.\n",
      "* The generated code is typically of high quality, requires minimal editing, and can significantly speed up the development process.\n",
      "\n",
      "**Benefits of Using LLM Models:**\n",
      "\n",
      "* **Increased Productivity:** LLMs automate repetitive coding tasks, freeing up developers to focus on complex tasks.\n",
      "* **Improved Code Quality:** LLMs generate code with consistent formatting and fewer errors, enhancing code maintainability.\n",
      "* **Reduced Development Time:** LLMs accelerate project completion by eliminating the need for manual code writing.\n",
      "* **Enhanced Creativity:** LLMs can suggest innovative solutions or code patterns that developers may not have considered.\n",
      "\n",
      "**How to Use LLM Models for Code Generation:**\n",
      "\n",
      "* **Identify the Input Prompt:** Clearly define the functionality or code snippet you want the LLM to generate.\n",
      "* **Choose an LLM Service:** Several LLM services are available, such as OpenAI Codex, Google Colab, and Amazon SageMaker.\n",
      "* **Write the Code Generation Code:** Use the LLM service's API or interface to submit the input prompt and receive the generated code.\n",
      "* **Review and Iterate:** Carefully review the generated code and make necessary modifications or provide additional context to the LLM for further refinement.\n",
      "\n",
      "**Example Use Cases:**\n",
      "\n",
      "* **Function Generation:** LLMs can generate functions for specific tasks based on natural language descriptions.\n",
      "* **Code Completion:** LLMs can automatically complete code fragments, reducing the need for manual typing.\n",
      "* **Bug Detection:** LLMs can identify potential bugs in code by analyzing patterns and comparing code to known bug repositories.\n",
      "* **Code Explanation:** LLMs can generate explanations for code snippets, enhancing understanding and documentation.\n",
      "\n",
      "**Conclusion:**\n",
      "\n",
      "LLM models are transformative tools for code generation, offering numerous benefits to developers. By leveraging their language understanding capabilities, LLMs automate tasks, improve code quality, accelerate development, and foster creativity. As LLM technology continues to advance, developers will increasingly rely on these models to enhance their productivity and drive innovation.\n"
     ]
    }
   ],
   "source": [
    "if api_key is not None:\n",
    "    gemini.configure(api_key=api_key)\n",
    "\n",
    "    # create a service instance    \n",
    "    model = gemini.GenerativeModel(model_name)\n",
    "    prompt = 'We are in a presentation about LLM models and how to use them to help developers generate code. Can you help us on the subject?'\n",
    "    \n",
    "    # generate content\n",
    "    result = model.generate_content(prompt)\n",
    "    print(result.text)\n",
    "else:\n",
    "    print('The key was not loaded')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing Prompts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```python\n",
      "def max_number(lst):\n",
      "  \"\"\"\n",
      "  Returns the biggest number from a list.\n",
      "\n",
      "  Args:\n",
      "    lst: A list of numbers.\n",
      "\n",
      "  Returns:\n",
      "    The biggest number in the list.\n",
      "  \"\"\"\n",
      "\n",
      "  max_num = lst[0]\n",
      "  for num in lst[1:]:\n",
      "    if num > max_num:\n",
      "      max_num = num\n",
      "\n",
      "  return max_num\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "bad_prompt = \"Write some code that select the biggest number from a list\"\n",
    "\n",
    "result = model.generate_content(bad_prompt)\n",
    "print(result.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```python\n",
      "def find_max_number(values: list[int]) -> int | None:\n",
      "    \"\"\"\n",
      "    Finds the largest integer in a list of integers.\n",
      "\n",
      "    Args:\n",
      "        values (list): A list of integers.\n",
      "\n",
      "    Returns:\n",
      "        The largest integer in the list, or None if the list is empty or null.\n",
      "    \"\"\"\n",
      "    if not values:\n",
      "        return None\n",
      "\n",
      "    return max(values)\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "improved_prompt = \"\"\"Write a Python function with the following specifications\n",
    "                    Use the name find_max_number. \n",
    "                    Use a list of integers as input, name it values.\n",
    "                    Return the largest integer in the list using the builtin api max().\n",
    "                    Set the correct data type for the input parameter.\n",
    "                    Document the arguments, function purpose and return type. \n",
    "                    Check for empty or null list to avoid rasing an exception and return none.\"\"\"\n",
    "\n",
    "result = model.generate_content(improved_prompt)\n",
    "print(result.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exit and remove the virtual environment\n",
    "\n",
    "```bash\n",
    "exit\n",
    "pipenv --rm\n",
    "```\n",
    "> Make sure to exit the pipenv shell and remove the virtual environment"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
