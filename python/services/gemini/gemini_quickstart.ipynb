{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to use the AI Gemini API\n",
    "\n",
    "## Prerequisites\n",
    "- Use Python 3.9\n",
    "- Install the google-generativeai SDK\n",
    "- Get an API key from Google AI Studio https://aistudio.google.com/app/apikey\n",
    "- Copy your key and move it to the home directory of the VM or device\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sys.version_info(major=3, minor=9, micro=5, releaselevel='final', serial=0)\n"
     ]
    }
   ],
   "source": [
    "# verify python 3.9\n",
    "import sys\n",
    "print(sys.version_info)\n",
    "assert sys.version_info >= (3, 9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upgrade to Python 3.9 Ubunto\n",
    "\n",
    "- Search if the version of python is available in the current Ubuntu repos\n",
    "\n",
    "```bash\n",
    "apt search python3.9\n",
    "```\n",
    "\n",
    "- if packages are listed. Install with the following command\n",
    "\n",
    "```bash\n",
    "sudo apt install python3.9\n",
    "```\n",
    "\n",
    "- If the package is not listed, download the entire file and install from the command line.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get your API key from Google AI Studio\n",
    "\n",
    "[https://aistudio.google.com/app/apikey](https://aistudio.google.com/app/apikey)\n",
    "\n",
    "- Copy the key\n",
    "\n",
    "## Update the API key in your environment\n",
    "\n",
    "Using a terminal, run the save_key.sh bash file and enter the key at the prompt.\n",
    "\n",
    "This script will do the following:\n",
    "\n",
    "- Create a $Home/.gcp folder\n",
    "- Save the API key in the gemini.key file by running this bash file\n",
    "- Add a new environment variable GEMINI_KEY\n",
    "\n",
    "```bash\n",
    "./save_key.sh\n",
    "```\n",
    "\n",
    "> For production environments, set the correct permissions for that file or use a keyvault (recommended)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup a virtual environment\n",
    "\n",
    "- We recommend the use of a virtual environment to run this.\n",
    "```bash\n",
    "pip install pipenv\n",
    "pipenv shell\n",
    "```\n",
    "\n",
    "> You can run this without `pipenv` by installing only the dependencies locally"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install the Gemini API dependencies from the terminal\n",
    "\n",
    "- Use PIPEnv to update the depencies\n",
    "```bash\n",
    "pipenv shell\n",
    "pipenv sync\n",
    "```\n",
    "> pipenv sync installs the dependencies from the Pipfile\n",
    "\n",
    "\n",
    "- Or manually install the dependencies (No pipEnv)\n",
    "\n",
    "## Install the API requests module\n",
    "```bash\n",
    "pipenv install -q google-generativeai\n",
    "pipenv install requests\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the code example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ozkary/.local/share/virtualenvs/python-dNT3Lhuf/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# import the GEMINI API\n",
    "import google.generativeai as gemini\n",
    "\n",
    "# get the key reference\n",
    "api_key = os.getenv('GEMINI_KEY')\n",
    "model_name = 'gemini-pro'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**What are LLM Models?**\n",
      "\n",
      "Large Language Models (LLMs) are advanced AI models trained on massive text datasets to understand and generate human-like language. These models include:\n",
      "\n",
      "* GPT-3\n",
      "* ChatGPT\n",
      "* BLOOM\n",
      "* Megatron-Turing NLG\n",
      "\n",
      "**How LLMs Can Help Developers Generate Code**\n",
      "\n",
      "LLMs can assist developers with the following coding tasks:\n",
      "\n",
      "* **Code Completion:** Suggesting the next line of code based on the context.\n",
      "* **Code Generation:** Generating entire code blocks according to a given description.\n",
      "* **Code Debugging:** Identifying and suggesting fixes for code errors.\n",
      "* **Code Refactoring:** Restructuring and improving the efficiency of existing code.\n",
      "* **Documentation Generation:** Creating detailed documentation for code modules and functions.\n",
      "\n",
      "**Benefits of Using LLMs for Code Generation**\n",
      "\n",
      "* **Increased Productivity:** LLMs automate code-related tasks, freeing up developers for more complex problem-solving.\n",
      "* **Improved Accuracy:** LLMs can generate high-quality code with low error rates.\n",
      "* **Faster Development:** LLMs can accelerate the development process by eliminating the need for manual coding.\n",
      "* **Enhanced Security:** LLMs can help identify and mitigate code vulnerabilities.\n",
      "\n",
      "**How to Use LLMs for Code Generation**\n",
      "\n",
      "1. **Choose an Appropriate LLM:** Select an LLM that is tailored to code generation tasks.\n",
      "2. **Provide Clear Instructions:** Input precise descriptions or code examples to guide the LLM.\n",
      "3. **Review and Refine:** Verify the generated code for accuracy and make necessary adjustments.\n",
      "4. **Integrate into Workflow:** Leverage tools and frameworks to seamlessly integrate LLM-generated code into your development pipeline.\n",
      "\n",
      "**Challenges and Considerations**\n",
      "\n",
      "* **Bias and Limitations:** LLMs may inherit biases from their training data and have limitations in generating certain types of code.\n",
      "* **Security Concerns:** Generated code should be thoroughly reviewed before implementation to prevent potential vulnerabilities.\n",
      "* **Ethical Implications:** LLMs raise ethical questions regarding the use of AI in code generation and the potential impact on the developer workforce.\n",
      "\n",
      "**Conclusion**\n",
      "\n",
      "LLM models have emerged as powerful tools that can assist developers in generating high-quality code. By leveraging LLMs, developers can improve their productivity, accuracy, and development speed. It is important to approach LLM-generated code with caution and to consider potential biases and ethical implications.\n"
     ]
    }
   ],
   "source": [
    "if api_key is not None:\n",
    "    gemini.configure(api_key=api_key)\n",
    "\n",
    "    # create a service instance    \n",
    "    model = gemini.GenerativeModel(model_name)\n",
    "    prompt = 'We are in a presentation about LLM models and how to use them to help developers generate code. Can you help us on the subject?'\n",
    "    \n",
    "    # generate content\n",
    "    result = model.generate_content(prompt)\n",
    "    print(result.text)\n",
    "else:\n",
    "    print('The key was not loaded')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing Prompts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```python\n",
      "def max_number(lst):\n",
      "  \"\"\"\n",
      "  Returns the biggest number from a list.\n",
      "\n",
      "  Args:\n",
      "    lst: A list of numbers.\n",
      "\n",
      "  Returns:\n",
      "    The biggest number in the list.\n",
      "  \"\"\"\n",
      "\n",
      "  max_num = lst[0]\n",
      "  for num in lst[1:]:\n",
      "    if num > max_num:\n",
      "      max_num = num\n",
      "\n",
      "  return max_num\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "bad_prompt = \"Write some code that select the biggest number from a list\"\n",
    "\n",
    "result = model.generate_content(bad_prompt)\n",
    "print(result.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```python\n",
      "def find_max_number(values: list[int]) -> int | None:\n",
      "    \"\"\"\n",
      "    Finds the largest integer in a list of integers.\n",
      "\n",
      "    Args:\n",
      "        values (list): A list of integers.\n",
      "\n",
      "    Returns:\n",
      "        The largest integer in the list, or None if the list is empty or null.\n",
      "    \"\"\"\n",
      "    if not values:\n",
      "        return None\n",
      "\n",
      "    return max(values)\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "improved_prompt = \"\"\"Write a Python function with the following specifications\n",
    "                    Use the name find_max_number. \n",
    "                    Use a list of integers as input, name it values.\n",
    "                    Return the largest integer in the list using the builtin api max().\n",
    "                    Set the correct data type for the input parameter.\n",
    "                    Document the arguments, function purpose and return type. \n",
    "                    Check for empty or null list to avoid rasing an exception and return none.\"\"\"\n",
    "\n",
    "result = model.generate_content(improved_prompt)\n",
    "print(result.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exit and remove the virtual environment\n",
    "\n",
    "```bash\n",
    "exit\n",
    "pipenv --rm\n",
    "```\n",
    "> Make sure to exit the pipenv shell and remove the virtual environment"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
